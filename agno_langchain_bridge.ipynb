{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Agno Bridge - Enhancing AI Agent Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This bridge did not exist....so I built it!\n",
    "\n",
    "**I asked myself a few questions while building this:**\n",
    "\n",
    "- Why can I not use my Langchain based code inside Agno-agi?\n",
    "- Why can I not use the more in depht Langchain functionalities, when I am building Agno-agi Agents?\n",
    "- Why are there not a way to get advanced Langchain functionalities with a pretty interface done by Agno-agi?\n",
    "\n",
    "**The solution was not out there so I built it myself!**\n",
    "- I could not find the answer to these three questions so I figured out a way for Agno-agi to use Langchain based functionalites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agno-agi documentation**\n",
    "- https://github.com/agno-agi/agno/tree/main\n",
    "- https://docs.agno.com/introduction\n",
    "\n",
    "**Langchain documentation**\n",
    "- https://github.com/langchain-ai\n",
    "- https://python.langchain.com/docs/introduction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain_Agno_Bridge dot png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's supercharge Agno-agi Agents with Langchain!\n",
    "\n",
    "### Overview  \n",
    "- This project explores how to supercharge Agno-agi Agents, by giving these Agents Langchain functionalities to complete automated advanced tasks more efficiently. \n",
    "- Building intelligent AI agents requires seamless interactions between large language models and external tools. This project helps aiding that process by exploring a bridge between two open source projects.\n",
    "\n",
    "### Why This Matters  \n",
    "- For AI leaders: This demonstrates how Langchain can streamline AI development, improving productivity and decision-making. Without sacrificing the visually pleasing and easily deployed Agents from Agno-agi. \n",
    "- For engineers: It provides a structured approach to integrating AI agents efficiently. Now with more tools and more functionalities. \n",
    "\n",
    "\n",
    "### **Key Highlights**\n",
    "- Uses Langchain to integrate AI models with real-world applications.  \n",
    "- Implements structured pipelines for building a Langchain class (Python class with Langchain ChatPromptTemplate and LLM) and then transforming this into an Agno-agi tool.\n",
    "- Designed with **modularity** and **scalability** in mind, and my implementation would be ideal for companies who need to do more data transformations before running the Agent.\n",
    "\n",
    "\n",
    "Whether you're a **manager exploring AI applications** or a **developer working on AGI projects**, this notebook serves as a **practical bridge** to more advanced AI agent architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain-ollama.png\n",
    "\n",
    "- Quick note to AI developers and hiring manangers, this whole project is made with local LLMs. More about this later "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** \n",
    "- Marcus Johansson \n",
    "\n",
    "**Reach out to me on my socials with your questions!**\n",
    "- https://x.com/marcusjihansson\n",
    "- https://www.linkedin.com/in/marcus-frid-johansson/\n",
    "\n",
    "- I am a technolgist at heart and I have experiece in AI tools and in building AI Agents\n",
    "- I am open for jobs as a Python developer, Python engineer or in finance related roles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the bridge - A quick walk through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "- For starters, I was supposed to create Langchain Agents to show my skills in this skills project.\n",
    "- But then I realized that Langchain is sort of confusing to build and run Agents in!\n",
    "\n",
    "**My grief with Langchain**\n",
    "- To the credit of the Langchain team and documentation it works great, but I had some issues in regards to running and building Lanchain Agents.\n",
    "- The reason for these issues boils down to the ever evolving Langchain documentation.\n",
    "- This means I was already looking for a simplified/more efficient approach.\n",
    "\n",
    "**Efficient Agent building**\n",
    "- So I found the Agno-agi project, while looking for more efficient ways of building Agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I had heard about Agno-agi..\n",
    "- I had heard about Agno-agi before and used it beofre when it was called Phidata.\n",
    "- I had tried Phidata, but as the project was new was I unable to build my custom clases and my custom tools. \n",
    "- So I at that time did not decide to use Phidata.\n",
    "\n",
    "**Why did I go back to Agno-agi?**\n",
    "- I struggled with building Langchain Agents as I did not like their implementation and their interface.\n",
    "- So after reading the Agno-agi documentation, reading Twitter/X posts and watching YouTube videos, I realized that the team at Agno-agi has done many\n",
    "improvements to the priror Phidata I had used!\n",
    "- I then tested small scale tools and and smaller Agents inside the Agno-agi framework and I really liked the front end user experience of building and \n",
    "using the Agno-agi framework as it looked visually pleasing to work with. This is huge for customers and builders!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agnet_call.png\n",
    "\n",
    "- Here is an example on what an Agent call would look like from Agno-agi with this Langchain bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this bridge?\n",
    "- I was unable to bridge my Langchain classes and use them inside Agno-agi!\n",
    "- I figured out a custom sollution where I was able to work in the Langchain syntax I had written into the Agno-agi Agent.\n",
    "- Now could I use the visually pleasing and easy to manange Agents in Agno-agi, with the advanced functionalities from Langchain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agent_response.png\n",
    "\n",
    "- Here is an example of what an Agent response would look like from Agno-agi and this Langchain bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My solution: (Step 1 out of 3)\n",
    "\n",
    "**A two LLM implementation:**\n",
    "\n",
    "1. Build a custom Python class, with a Langchain based component to analyze the data (this is LLM 1)\n",
    "2. Build a Python function that runs the custom Python class, when calling it\n",
    "3. Agno-agi Agent can now call this Python function when running the Agent, as Agno-agi uses Python functions in their tool calls (this is LLM 2)\n",
    "\n",
    "- In the next section, am I going to explain why we need a two LLM solution\n",
    "\n",
    "- This picture below explains how this is implemented\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_diagram.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My solution continues (Step 2 out of 3)\n",
    "\n",
    "**Why do we need a two LLM solution?:**\n",
    "\n",
    "- LangChain and Agno-agi adopt fundamentally different approaches to leveraging LLMs. LangChain's ChatOllama is optimized for conversational AI and complex reasoning tasks, making it ideal for chatbot-like applications: \n",
    "1. In contrast, Agno-agi focuses on modular, flexible architectures for building AI agents, emphasizing tool integration and memory retention \n",
    "2. These differences in design philosophy lead to incompatible interfaces when attempting to use LangChain's LLM within Agno-agi's framework.\n",
    "\n",
    "\n",
    "**I found this implementation error:**\n",
    "\n",
    "- Agno-agi is unable to directly invoke certain functions that are compatible with LangChain's ChatOllama\n",
    "- When these functions are used as tools within Agno-agi's agent workflow, an LLM implementation error occurs. This is likely due to differences in how the two frameworks handle tool registration, API calls, or data formatting.\n",
    "\n",
    "**Explanation of the Problem:**\n",
    "\n",
    "- LangChain's LLM operates through a conversational interface designed for maintaining context and coherence in dialogues. Agno-agi, on the other hand, uses a modular architecture tailored for goal-oriented tasks and tool integration. These divergent approaches result in incompatible interfaces, leading to errors when attempting to combine them.\n",
    "\n",
    "\n",
    "**This can be sovled with my custom implementation**\n",
    "\n",
    "- This is why it is important to add the LLM class from Langchain into the tool function, because now can we circumvent this eror by calling the functions seperately in and then feed this data to the Agent.\n",
    "\n",
    "\n",
    "**Specifically:**\n",
    "\n",
    "- The LangChain LLM will preprocess the input data and generate responses independently.\n",
    "- These responses will then be passed to Agno-agi's agent workflow via the tool function in Agent.py.\n",
    "- By decoupling the LLM processing from Agno-agi's native tool invocation, we can circumvent the implementation error and ensure seamless integration.\n",
    "\n",
    "**Implementation Fix:**\n",
    "\n",
    "- In the picture down below do I show how this implementation eror can be solved, by feeding the tool outputs into the Agent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diagram.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Solution (Step 3 out of 3)\n",
    "\n",
    "**Impelementation continues:**\n",
    "\n",
    "- This data fed to the Agent, was made by prompt engineering the Agent to incorporate this data into its answer!\n",
    "-  Now can the Agno-agi Agent use the collected data from the function and then do an analysis.\n",
    "\n",
    "- This print screen from the Agent (used in the example later on) shows how this is implemented by running the induvidual functions and then prompting the Agent to analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example_usage.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs used in this project\n",
    "\n",
    "**Local LLMs**\n",
    "- The LLMs used in this project are all local.\n",
    "- They do not need an online server and the implementation is free, you do not need an OpenAI api key or a Claude api key.\n",
    "- This is both exceptional for students (who wants to lower costs) but also for companies (where security is a key component), but of course are you able to add and change the LLMs used in this project with your own!\n",
    "\n",
    "**LLMs used**\n",
    "- I have used Ollama to do my Langchain implementation. (https://ollama.com/ , https://github.com/ollama/ollama)\n",
    "- I have used LM Studio for my Agent implementation. (https://lmstudio.ai/, https://github.com/lmstudio-ai)\n",
    "\n",
    "- Both of these are local ways of running a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for reading so far! \n",
    "\n",
    "- Thank you for reading, this is where the big picture ends and I am going to go through code and examples of how to implement this. \n",
    "- I encourage you to keep reading as in the next section am I going to explain how to build and use Langchain capabilities inside an Agno-agi Agent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code and a closer example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My custom classes: \n",
    "\n",
    "**To Long Did Not Read**\n",
    "- These custom classes are Python classes, where some of them have a Langchain implementation.\n",
    "- If they have their own Langchain implementation, they also implement their own Langchain LLM.\n",
    "- These custom classes needs their own Langchain LLM implementation, so that the tool is able to run the class before feeding the data into the Agent.\n",
    "\n",
    "**The value of prompt engineering**\n",
    "- We can also gain additional value from prompt engineering by prompting the LLM inside this class effectively, for example:\n",
    "\n",
    "1. Analyze the sentiment data and then collect insights.\n",
    "2. Analyze the price data and explain vissible price trends.\n",
    "3. Analyze the sentiment data for a ticker symbol and tell me if this sentiment is possitive or negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About these classes:**\n",
    "- My custom classes were built for the use case of Finance and financial analysis, both in the case for long term investments and in the case for short term trading. \n",
    "- This is not financial advice, this is just some examples of my custom classes I have built into tools to use with Agno-agi.\n",
    "\n",
    "- Some of these classes requires an API-key and these are: \n",
    "1. ALPACA; Collects stock and crypto price data.\n",
    "2. FINLIGHT_API_KEY; Collects sentiment data.\n",
    "3. ALPHA_VANTAGE_API_KEY; Collects financial statements.\n",
    "\n",
    "\n",
    "**What is this example about?**\n",
    "\n",
    "- The three classes this example is going to focus on are AlphaVantageClient, AssetPriceFetcher and ContextDataTool:\n",
    "1. The AlphaVantageClient is a class that fetches financial statements and then analyses them with an LLM, after this analysis is the data fed to the Agent.\n",
    "2. The AssetPriceFetcher fetches data from Alpaca and then stores this data to be used by the Agent.\n",
    "3. The ContextDataTool is a class that fetches sentiment data for a ticker symbol and then analyses this sentiment data with the LLM, before this analysis is passed to the Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Langchain class collects fundamental stock data from Alphavantage, then uses an llm to analyze the results\n",
    "# The fundamental stock data collected is: income statement, balance sheet, cash flow statement and earnings \n",
    "# It is possible to run this code as its own class and use it to collect data, but it is more powerful inside the Agent\n",
    "\n",
    "# Libraries\n",
    "from typing import Dict, Any, Optional\n",
    "import pprint\n",
    "\n",
    "# LangChain libraries for building the Agent structure\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "alpha_vantage_key = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "\n",
    "# Initialize the model\n",
    "llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "# Analyze fundamental data for a compnay based on their financial statements\n",
    "class AlphaVantageClient:\n",
    "    BASE_URL = \"https://www.alphavantage.co/query\"\n",
    "    RATE_LIMIT_DELAY = 15  # Alpha Vantage's free tier has a rate limit of 5 requests per minute\n",
    "\n",
    "    def __init__(self, alpha_vantage_key: Optional[str] = None):\n",
    "        if not alpha_vantage_key:\n",
    "            raise ValueError(\"Alpha Vantage API key is required.\")\n",
    "        self.alpha_vantage_key = alpha_vantage_key  # Store API key in an instance variable\n",
    "\n",
    "    def _fetch_data(self, function: str, symbol: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Generic method to fetch financial statement data from Alpha Vantage API.\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"function\": function,\n",
    "            \"symbol\": symbol,\n",
    "            \"apikey\": self.alpha_vantage_key\n",
    "        }\n",
    "        \n",
    "        response = requests.get(self.BASE_URL, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"Error Message\" in data:\n",
    "                print(f\"Error: {data['Error Message']}\")\n",
    "                return None\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"Error: HTTP status code {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "    def get_income_statement(self, symbol: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch the last 2 quarterly income statements.\"\"\"\n",
    "        time.sleep(self.RATE_LIMIT_DELAY)  # Respect API rate limits\n",
    "        data = self._fetch_data(\"INCOME_STATEMENT\", symbol)\n",
    "        if data and \"quarterlyReports\" in data:\n",
    "            return {\"symbol\": symbol, \"quarterlyReports\": data[\"quarterlyReports\"][:2]}\n",
    "        return None\n",
    "\n",
    "    def get_balance_sheet(self, symbol: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch the last 2 quarterly balance sheets.\"\"\"\n",
    "        time.sleep(self.RATE_LIMIT_DELAY)\n",
    "        data = self._fetch_data(\"BALANCE_SHEET\", symbol)\n",
    "        if data and \"quarterlyReports\" in data:\n",
    "            return {\"symbol\": symbol, \"quarterlyReports\": data[\"quarterlyReports\"][:2]}\n",
    "        return None\n",
    "\n",
    "    def get_cash_flow_statement(self, symbol: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch the last 2 quarterly cash flow statements.\"\"\"\n",
    "        time.sleep(self.RATE_LIMIT_DELAY)\n",
    "        data = self._fetch_data(\"CASH_FLOW\", symbol)\n",
    "        if data and \"quarterlyReports\" in data:\n",
    "            return {\"symbol\": symbol, \"quarterlyReports\": data[\"quarterlyReports\"][:2]}\n",
    "        return None\n",
    "\n",
    "    def get_earnings(self, symbol: str) -> Optional[Any]:\n",
    "        \"\"\"Fetch the last 2 quarterly earnings reports.\"\"\"\n",
    "        time.sleep(self.RATE_LIMIT_DELAY)\n",
    "        data = self._fetch_data(\"EARNINGS\", symbol)\n",
    "        if data and \"quarterlyEarnings\" in data:\n",
    "            return data[\"quarterlyEarnings\"][:2]\n",
    "        return None\n",
    "\n",
    "    def run_analysis(self, symbol: str) -> dict:\n",
    "        \"\"\"Run analysis by fetching all financial data for a given ticker.\"\"\"\n",
    "        print(f\"Fetching financial data for {symbol}...\")\n",
    "        data = {\n",
    "            \"income_statement\": self.get_income_statement(symbol),\n",
    "            \"balance_sheet\": self.get_balance_sheet(symbol),\n",
    "            \"cash_flow\": self.get_cash_flow_statement(symbol),\n",
    "            \"earnings\": self.get_earnings(symbol)\n",
    "        }\n",
    "        return data\n",
    "\n",
    "    def get_fundamental_analysis(self, symbol: str, llm) -> dict:\n",
    "        \"\"\"Full analysis pipeline with summarization, including financial data from run_analysis.\"\"\"\n",
    "        financial_data = self.run_analysis(symbol)\n",
    "\n",
    "        if not financial_data:\n",
    "            return {\"error\": \"No financial data available\"}\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"\"\"You are a seasoned financial trader with expertise in analyzing fundamental company data such as income statements,\n",
    "            balance sheets, cash flow statements, and earnings data.\n",
    "            Your task is to evaluate the financial data and determine whether it could have a **direct or indirect impact** on the price of the asset identified by the ticker \"{symbol}\".\n",
    "            Consider broader market trends, sector dynamics, and macroeconomic factors when evaluating the financial performance of the asset identified by the ticker \"{symbol}\".\n",
    "            Ensure your recommendations are concise, well-reasoned, and aligned with the provided timeframe.\n",
    "            The data collected is for the last two quarters and your analysis should be focused on how the company \n",
    "            is financially positioned over the past two quarters and how this could impact the future price of the asset identified by the ticker \"{symbol}\". \n",
    "            Your analysis should also include any potential risks or uncertainties associated with the company's financial performance.\"\"\"),\n",
    "            \n",
    "            (\"user\", \"\"\"Analyze the following financial data:\n",
    "            {financial_data}\n",
    "\n",
    "            Answer the following questions:\n",
    "            - Key insights and how they relate to \"{symbol}\".\n",
    "            - Direct or indirect impact on \"{symbol}\".\n",
    "            - How these insights could influence the price in the future.\n",
    "            - Sector, market, and industry trends affecting \"{symbol}\".\n",
    "            - Risks or uncertainties associated with your recommendation.\n",
    "\n",
    "            Make sure all your analysis considers both **direct** and **indirect** effects on \"{symbol}\".\"\"\")\n",
    "        ])\n",
    "\n",
    "        # ðŸ”¥ Fix: Properly pass financial_data and symbol to the prompt\n",
    "        input_variables = {\n",
    "            \"symbol\": symbol,\n",
    "            \"financial_data\": financial_data  # Pass the financial data to the LLM\n",
    "        }\n",
    "\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        fundamental_analysis = chain.invoke(input_variables) \n",
    "        return fundamental_analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This python class that collects market data from Alpaca \n",
    "# This class can also be run as a stand alone class\n",
    "\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from alpaca.data.historical.stock import StockHistoricalDataClient\n",
    "from alpaca.data.historical.crypto import CryptoHistoricalDataClient\n",
    "from alpaca.data.requests import CryptoBarsRequest\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "import datetime\n",
    "from datetime import timedelta, datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import pandas as pd\n",
    "import pprint \n",
    "from typing import Union\n",
    "\n",
    "# Safely access API keys using .get()\n",
    "import os \n",
    "\n",
    "alpaca_key = os.getenv('ALPACA_KEY')\n",
    "alpaca_secret = os.getenv('ALPACA_SECRET')\n",
    "\n",
    "\n",
    "class AssetPriceFetcher:\n",
    "    def __init__(self, alpaca_key: str, alpaca_secret: str):\n",
    "        \"\"\"\n",
    "        Initialize the StockAnalyzer with Alpaca API credentials.\n",
    "        \"\"\"\n",
    "        self.alpaca_key = alpaca_key\n",
    "        self.alpaca_secret = alpaca_secret\n",
    "\n",
    "    def fetch_ohlcv(self, symbol: str, days: int = 30, timeframe: TimeFrame = TimeFrame.Day, limit: int = None) -> Union[pd.DataFrame, str]:\n",
    "        \"\"\"\n",
    "        Fetch historical stock bars from Alpaca API.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create Alpaca client\n",
    "            client = StockHistoricalDataClient(self.alpaca_key, self.alpaca_secret)\n",
    "\n",
    "            # Set timezone to New York\n",
    "            now = datetime.now(ZoneInfo(\"America/New_York\"))\n",
    "\n",
    "            # Prepare request parameters\n",
    "            if limit is None:\n",
    "                limit = days\n",
    "\n",
    "            req = StockBarsRequest(\n",
    "                symbol_or_symbols=[symbol],\n",
    "                timeframe=timeframe,\n",
    "                start=now - timedelta(days=days),\n",
    "                limit=limit\n",
    "            )\n",
    "\n",
    "            # Fetch stock bars\n",
    "            bars = client.get_stock_bars(req)\n",
    "            df = bars.df\n",
    "\n",
    "            # Ensure VWAP is included\n",
    "            if \"vwap\" not in df.columns:\n",
    "                return \"Error: VWAP data not available in fetched data.\"\n",
    "\n",
    "            # Reset index and parse timestamp as datetime\n",
    "            df = df.reset_index()\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df.set_index('timestamp', inplace=True)  # Set timestamp as the index\n",
    "\n",
    "            return df  # Return as a DataFrame for further processing\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error fetching OHLCV data: {str(e)}\"\n",
    "\n",
    "    def fetch_ohlcv_crypto(self, symbol: str, days: int = 30, timeframe: TimeFrame = TimeFrame.Day, limit: int = None) -> Union[pd.DataFrame, str]:\n",
    "        \"\"\"\n",
    "        Fetch historical stock bars from Alpaca API.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create Alpaca client\n",
    "            client = CryptoHistoricalDataClient(self.alpaca_key, self.alpaca_secret)\n",
    "\n",
    "            # Set timezone to New York\n",
    "            now = datetime.now(ZoneInfo(\"America/New_York\"))\n",
    "\n",
    "            # Prepare request parameters\n",
    "            if limit is None:\n",
    "                limit = days\n",
    "\n",
    "            req = CryptoBarsRequest(\n",
    "                symbol_or_symbols=[symbol],\n",
    "                timeframe=timeframe,\n",
    "                start=now - timedelta(days=days),\n",
    "                limit=limit\n",
    "            )\n",
    "\n",
    "            # Fetch stock bars\n",
    "            bars = client.get_crypto_bars(req)\n",
    "            df = bars.df\n",
    "\n",
    "            # Ensure VWAP is included\n",
    "            if \"vwap\" not in df.columns:\n",
    "                return \"Error: VWAP data not available in fetched data.\"\n",
    "\n",
    "            # Reset index and parse timestamp as datetime\n",
    "            df = df.reset_index()\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df.set_index('timestamp', inplace=True)  # Set timestamp as the index\n",
    "\n",
    "            return df  # Return as a DataFrame for further processing\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error fetching OHLCV data: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Langchain class analyzes the senitment for a ticker between 2 dates and then feeds it to an LLM \n",
    "# It collects data and after doing some data modeling can the user ask questions from the articles collected \n",
    "# The api used here is Finlight\n",
    "# This class can also be run as a stand alone class\n",
    "\n",
    "# Libraries \n",
    "from typing import Optional\n",
    "from finlight_client import FinlightApi\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "import os \n",
    "import pprint\n",
    "\n",
    "news_key = os.getenv(\"FINLIGHT_API_KEY\")\n",
    "\n",
    "# Initialize the qwen model\n",
    "\n",
    "llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "class ContextDataTool:\n",
    "    def __init__(self, news_key: Optional[str] = None):\n",
    "        if not news_key:\n",
    "            raise ValueError(\"Finlight API key is required.\")\n",
    "        self.news_key = news_key  # Store API key in an instance variable\n",
    "\n",
    "    def get_news(self, symbol: str, start_date: str, end_date: str, limit: int = 20) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Fetch financial news for a given stock symbol from Finlight API.\n",
    "\n",
    "        :param symbol: Stock symbol of the company\n",
    "        :param start_date: Start date of the news\n",
    "        :param end_date: End date of the news\n",
    "        :param limit: Number of articles to fetch\n",
    "        :return: The news content as a string\n",
    "        \"\"\"\n",
    "        config = {\"api_key\": self.news_key}\n",
    "        client = FinlightApi(config)\n",
    "\n",
    "        params = {\n",
    "            \"query\": symbol,\n",
    "            \"language\": \"en\",\n",
    "            \"from\": start_date,\n",
    "            \"to\": end_date,\n",
    "            \"limit\": limit\n",
    "        }\n",
    "\n",
    "        # Fetch articles\n",
    "        articles = client.articles.get_extended_articles(params)\n",
    "\n",
    "        if not articles or \"articles\" not in articles:\n",
    "            return None\n",
    "\n",
    "        content_str = \" \".join(article[\"content\"] for article in articles[\"articles\"] if \"content\" in article)\n",
    "\n",
    "        print(\"Number of articles:\", len(articles[\"articles\"]))\n",
    "\n",
    "        return content_str\n",
    "\n",
    "    def get_ticker_context(self, symbol: str, start_date: str, end_date: str, llm) -> dict:\n",
    "        \"\"\"Full analysis pipeline with summarization\"\"\"\n",
    "        # Fetch news content\n",
    "        content_str = self.get_news(symbol, start_date, end_date)\n",
    "\n",
    "        # Check if content is available\n",
    "        if not content_str:\n",
    "            return {\"error\": \"No news data available\"}\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"\"\"You are a seasoned financial trader with expertise in analyzing news and market data to inform trading decisions.\n",
    "            Your task is to evaluate the provided data and determine whether it could have an **indirect impact** on the price of the asset identified by the ticker \"{symbol}\".\n",
    "            While the data may not be directly related to \"{symbol}\", it could still influence the asset's price through broader market trends, sector dynamics, or macroeconomic factors.\n",
    "            Keep in mind that the analysis should strictly consider data between {start_date} and {end_date}, as no future data is available.\n",
    "            Ensure your recommendations are concise, well-reasoned, and aligned with the timeframe and context provided.\"\"\"),\n",
    "\n",
    "            (\"user\", f\"\"\"Analyze the following data:\\n\\n{content_str}\\n\\n\n",
    "\n",
    "            Answer the following questions:\n",
    "            - Key insights from the data and how they relate to \"{symbol}\".\n",
    "            - Whether the data has a **direct** or **indirect** impact on \"{symbol}\".\n",
    "            - How these insights could influence the price or market sentiment of \"{symbol}\".\n",
    "            - What are the sector trends that could have an impact on \"{symbol}\". If the data has no direct or indirect impact on \"{symbol}\", then I will not make a recommendation.\n",
    "            - What are the market trends and macroeconomic factors that could have an impact on \"{symbol}\"\n",
    "            and which of those factors could have a **direct** or **indirect** impact on \"{symbol}\". If the data has no direct or indirect impact on \"{symbol}\", then I will not make a recommendation.\n",
    "            - What are industry trends that could have an impact on \"{symbol}\". If the data has no direct or indirect impact on \"{symbol}\", then I will not make a recommendation.\n",
    "            - Any risks or uncertainties associated with your recommendation.\n",
    "\n",
    "            Remember, this analysis is based on data between {start_date} and {end_date}, and the recommendation assumes you would act at the {end_date} of this analysis.\n",
    "            Make sure all your analysis considers both **direct** and **indirect** effects on \"{symbol}.\" \"\"\")\n",
    "        ])\n",
    "\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "        input_variables = {\n",
    "            \"symbol\": symbol,\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"input\": content_str\n",
    "        }\n",
    "\n",
    "        ticker_context = chain.invoke(input_variables)\n",
    "\n",
    "        return ticker_context\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Custom Tool implementation: \n",
    "\n",
    "- Remember that the tools are just Python functions! \n",
    "- My implementation matters because I have here implemented a way for the Agent to use the data collected by my custom classes.\n",
    "- Now when this class includes data, a prompt and is analyzed by the LLM can this be passed to the Agent to create actionable insights.\n",
    "- The only thing the tool does is that it runs this class as a function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Financial Statements Tool with Rate Limit Handling**\n",
    "\n",
    "- Down below is an example of a tool function, which initialize the LLM and the custom class: \n",
    "\n",
    "function_call.png\n",
    "\n",
    "\n",
    "**Additional comments to explain this example further**\n",
    "\n",
    "1. Here is the LLM initialized. So that these classes can run independently as functions, and then analyze the data they collect. \n",
    "- Rememver that the LLM here is in **Langchain format** (gemma = ChatOllama(model=\"gemma3:1b\")) and not through the way Agno-agi uses it.\n",
    "- This is as this class inhirits from Langchain, and as the data is analyzed with for example a ChatPromptTemplate does this function also have to call the LLM in Langchain format.\n",
    "- The LLM inside this tool can not be in the Agno-agi format (explained here \"My solution continues (Step 2 out of 3)\")\n",
    "\n",
    "2. Inside the tool is the custom classes I created and this class requries the Langchain LLM to be initialized. \n",
    "\n",
    "3. Running the analysis is done as simple as running the class, the only thing that has changed is that this class is now running inside a function.\n",
    "\n",
    "4. The tool then returns the result from the analysis as a string to then be fed into the Agent for further analysis.\n",
    "\n",
    "5. Error handling in these functions are key, as we can then track if the Agent uses this in its response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is the model initialize here and why can I not only initialize the model as llm=llm?**\n",
    "\n",
    "- The reason for initializing the model fully here is because then can the tool be imported directly into the Agent and we do not need to import the llm separetly\n",
    "- Yes, there is probably a way to have the model as variable, but when running the script could I see some errors and this was the simplest approach\n",
    "\n",
    "- Simple approach = good approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Statements Tool with Rate Limit Handling\n",
    "def fundamental_analysis_tool(symbol: str) -> str:\n",
    "    \"\"\"Analyzes fundamental compandy data (balance sheets, income statements, cash flow statements, earnings) for investment insights.\"\"\"\n",
    "    try:\n",
    "        llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "        client = AlphaVantageClient(alpha_vantage_key)\n",
    "        fundamental_data=client.get_fundamental_analysis(symbol, llm)\n",
    "        return fundamental_data\n",
    "    except Exception as e:\n",
    "        return f\"Data error: {str(e)}\" \n",
    "\n",
    "# Fetch asset price for Stocks\n",
    "def get_asset_price_stock(symbol: str) -> str:\n",
    "    \"\"\"Analyzes technical indicators for an asset to create a trading or investment strategy.\"\"\"\n",
    "    try:\n",
    "        analyzer = AssetPriceFetcher(alpaca_key, alpaca_secret)\n",
    "        asset_price=analyzer.fetch_ohlcv(symbol)\n",
    "        return {\"analysis\": asset_price}\n",
    "    except Exception as e:\n",
    "        return f\"Data error: {str(e)}\" \n",
    "    \n",
    "\n",
    "# Sentiment Analysis Tool\n",
    "def sentiment_analysis_tool(symbol: str, start_date: str, end_date: str) -> str:\n",
    "    \"\"\"Fetches news and analyzes context for a stock.\"\"\"\n",
    "    try:\n",
    "        tool = ContextDataTool(news_key)\n",
    "        llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "        context_data = tool.get_ticker_context(symbol, start_date, end_date, llm)\n",
    "        return {\"analysis\": context_data}\n",
    "    except Exception as e:\n",
    "        return f\"Data error: {str(e)}\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents: \n",
    "\n",
    "\n",
    "**Overview on how to build an agent:**\n",
    "- Initialize the LLM which is used by the Agent to do the analysis. \n",
    "- Initialize the Agent and build the agent object, which is the same as building any other Agno-agi Agent. \n",
    "- The only difference is that we can not add the tool calls, as we are adding the tool calls separately at a later stage.\n",
    "- After we have set up the Agent, do we need to set up the variables we need in our tool calls. \n",
    "- Then are we able to build our tool calls. \n",
    "\n",
    "**How can we connect the Agent to the tools?**\n",
    "- We can actually do this through prompting engineering!\n",
    "\n",
    "\n",
    "**How is this set up? -- in a variable called analysis_prompt**\n",
    "\n",
    "analysis_prompt.png\n",
    "\n",
    "\n",
    "- This variable includes a prompt string that is fed into the agent.\n",
    "- This prompt string asks the Agent to use the output from the tools to create an analysis.\n",
    "\n",
    "- This now means; that all the outputs from each tool is now passed together with the prompt string into the Agent as a variable.\n",
    "\n",
    "Now is the Agent able to run based on this \"analysis_prompt\".\n",
    "\n",
    "**The value of prompt engineering**\n",
    "- We can also gain additional value from prompt engineering by prompting the Agent itself to \"analyze the data and then do X\" for example: \n",
    "\n",
    "1. Analyze the data (from each tool) and then collect insights.\n",
    "2. Analyze the data (from each tool) and then do a risk assessment.\n",
    "3. Analyze the data (from each tool) and then show relationships between the data and create actionable insights.\n",
    "\n",
    "- This means that we gain the value of prompt engineering 2 times: one time by effectively prompting the Langchain model and another time by effectively prompting the model to run the Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching financial data for META...\n"
     ]
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.openai.like import OpenAILike\n",
    "\n",
    "# Initialize the model\n",
    "model = OpenAILike(\n",
    "    base_url=\"http://localhost:1234/v1\",  # LM Studio's local server\n",
    "    api_key=\"lm-studio\",  # LM Studio doesn't require a real API key\n",
    "    id=\"gemma-3-1b-it\"  # model's API identifier in LM Studio\n",
    ")\n",
    "\n",
    "\n",
    "# Follow Agno-agi set ups for building an Agent \n",
    "# But what this implementation does differently is that it does not include the tool calls, as we described above \n",
    "# We instead pass the tool calls at a later stage \n",
    "\n",
    "#Initialize the agent                                                      \n",
    "agent = Agent(\n",
    "    name=\"Macro AI Agent\",\n",
    "    model=model,\n",
    "    instructions=[\"Analyze the data from each tool and make a combined analysis\"],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "# First we need to define the variables we need for our tool calls \n",
    "symbol = \"META\" \n",
    "start_date = \"2025-03-14\"\n",
    "end_date = \"2025-03-24\"\n",
    "\n",
    "# Define the functions/tools to run with the Agent \n",
    "\n",
    "fundamental_analysis = fundamental_analysis_tool(symbol)                                    \n",
    "price = get_asset_price_stock(symbol)\n",
    "sentiemnt = sentiment_analysis_tool(symbol, start_date, end_date)                                     \n",
    "\n",
    "\n",
    "# Combine analyses into a single structured prompt                         \n",
    "analysis_prompt = f\"\"\"\n",
    "# Analysis Request for {symbol}\n",
    "\n",
    "Please analyze the following data and create a comprehensive assessment for {symbol}.\n",
    "\n",
    "## Fundamental Analysis\n",
    "{fundamental_analysis}\n",
    "\n",
    "## Asset Price\n",
    "{price}\n",
    "\n",
    "## Sentiment Analysis\n",
    "{sentiemnt}\n",
    "\n",
    "Please synthesize this information into a cohesive analysis that highlights key insights, asset price sentiment, potential risks, \n",
    "and opportunities in relationship to the asset price. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Now are we ready to pass run the agent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can run the agent normally if we are running this agent in a dedicated .py file \n",
    "\n",
    "#macro_agent.print_response(analysis_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.run(analysis_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Okay, let's synthesize this data and create a comprehensive assessment for \"\n",
      " 'META. Hereâ€™s a breakdown of the findings, organized with markdown '\n",
      " 'formatting:\\n'\n",
      " '\\n'\n",
      " '**I. Overall Situation â€“ A Data-Driven Assessment**\\n'\n",
      " '\\n'\n",
      " 'The data reveals a complex situation centered around connection issues with '\n",
      " \"META's APIs.  There are significant challenges in retrieving data, \"\n",
      " 'indicating potential instability or limitations within the data feeds.  '\n",
      " 'While the asset price data appears relatively stable (recent data), the API '\n",
      " 'connectivity problems are raising red flags and warrant immediate '\n",
      " 'investigation. The error messages suggest network-level issues, which could '\n",
      " 'be exacerbated by intermittent service disruptions.\\n'\n",
      " '\\n'\n",
      " '**II. Detailed Analysis of Each Data Source:**\\n'\n",
      " '\\n'\n",
      " '* **Fundamental Analysis:** This data point is a critical indicator.  The '\n",
      " '\"Error fetching OHLCV data\" suggests a fundamental issue â€“ the META API '\n",
      " 'isnâ€™t delivering the necessary information for its analysis. The repeated '\n",
      " '`NewConnectionError` strongly hints at a persistent problem, potentially '\n",
      " \"linked to network latency or temporary issues with META's servers.\\n\"\n",
      " '\\n'\n",
      " '* **Asset Price:** The asset price data is currently stable, which is '\n",
      " 'reassuring, but it doesnâ€™t provide context.  The fact that the API '\n",
      " 'connectivity problems *also* occur suggests this might be a secondary issue, '\n",
      " 'potentially masking a deeper underlying problem affecting the price itself.  '\n",
      " \"It's important to understand if there are any broader market trends \"\n",
      " \"impacting META's stock value.\\n\"\n",
      " '\\n'\n",
      " '* **Sentiment Analysis:** The sentiment analysis data is equally concerning. '\n",
      " 'The repeated `NewConnectionError` reinforces that these API connections are '\n",
      " 'unreliable and require attention.  The intermittent nature of the errors '\n",
      " 'suggests potential issues with the API itself, rather than a general market '\n",
      " 'downturn.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '**III. Combined Analysis & Key Insights**\\n'\n",
      " '\\n'\n",
      " \"Here's a synthesis of the combined analysis:\\n\"\n",
      " '\\n'\n",
      " '1. **Connectivity Bottleneck:** The core issue is a persistent network '\n",
      " \"problem affecting METAâ€™s APIs. This isn't just a temporary glitch; it \"\n",
      " 'represents a fundamental limitation in how the platform delivers data.  The '\n",
      " 'repeated `NewConnectionError` indicates this is a recurring, but not '\n",
      " 'necessarily severe, issue.\\n'\n",
      " '\\n'\n",
      " '2. **Potential Impact on Asset Price:** While the price seems stable now, '\n",
      " 'the API instability *could* have subtle consequences. If the API is causing '\n",
      " 'delays or inaccuracies in the price data, it could impact investor '\n",
      " 'confidence and potentially lead to short-term volatility.  A sustained '\n",
      " 'inability to get real-time data could negatively affect trading decisions.\\n'\n",
      " '\\n'\n",
      " '3. **Risk Assessment:**\\n'\n",
      " '    * **Operational Risk:** The API connectivity problems pose a significant '\n",
      " 'operational risk for META. It disrupts the ability to monitor the stockâ€™s '\n",
      " 'performance, which is crucial for investors and analysts.\\n'\n",
      " '    * **Data Integrity Risk:** Inaccurate or delayed data could be '\n",
      " 'misinterpreted, leading to flawed investment decisions.\\n'\n",
      " '    * **Reputational Risk (Potential):** If the API issues are prolonged, it '\n",
      " \"could damage META's brand reputation as a reliable information provider.\\n\"\n",
      " '\\n'\n",
      " '4. **Opportunities â€“ Investigation & Mitigation:**\\n'\n",
      " '   * **Root Cause Analysis:**  Immediately investigate why these API '\n",
      " 'connections are failing. Possible causes include:\\n'\n",
      " '       * Network congestion at METAâ€™s servers.\\n'\n",
      " '       * Temporary service outages.\\n'\n",
      " \"       * Changes in META's infrastructure.\\n\"\n",
      " '   * **Monitoring & Alerting:** Implement robust monitoring of the APIs to '\n",
      " 'detect failures proactively. Set up alerts for connectivity issues.\\n'\n",
      " '   * **Rate Limiting/Retry Mechanisms:** Consider implementing rate limiting '\n",
      " 'or retry mechanisms on the API side to handle transient connection errors '\n",
      " 'gracefully, preventing them from cascading into larger problems.\\n'\n",
      " '   * **API Testing & Validation:**  Thoroughly test the APIs with different '\n",
      " 'tools and scenarios to identify any potential vulnerabilities.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '**IV. Recommendations**\\n'\n",
      " '\\n'\n",
      " '* **Prioritize Investigation:** Allocate resources (engineering team time) '\n",
      " 'to diagnose and resolve the API connectivity issues.\\n'\n",
      " '* **Communication:** Communicate the issue to stakeholders â€“ investors, '\n",
      " 'analysts, and internal teams â€“ to manage expectations.\\n'\n",
      " '* **Contingency Planning:** Develop a contingency plan in case the '\n",
      " 'connection problems become more frequent or prolonged.\\n'\n",
      " '\\n'\n",
      " '**V. Further Research (Beyond Initial Analysis)**\\n'\n",
      " '\\n'\n",
      " \"*   Check META's official documentation for API usage guidelines and \"\n",
      " 'troubleshooting procedures.\\n'\n",
      " '*   Analyze similar API connectivity issues reported by other users.\\n'\n",
      " '*   Examine METAâ€™s recent updates to its API infrastructure.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " 'Let me know if you would like me to elaborate on any specific aspect of this '\n",
      " 'analysis, such as the potential impact on trading strategies or specific '\n",
      " 'technical considerations.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Next Steps  \n",
    "\n",
    "\n",
    "### Summary  \n",
    "- This project successfully demonstrated how LangChain can be used to create an AI-powered bridge for Agno-agi in for example the use case finance and data analysis. But, this can be used in any use case as the implementation is just Python classes with Langchain and running Agents with Agno-agi.\n",
    "- There are other functions and classes I have exprimented with where the data has been collected from a csv file or from a PDF to get actionable insights with the LLM.\n",
    "\n",
    "**Why it matters:** \n",
    "- This approach improves AI agent efficiency and sets the foundation for AGI development. \n",
    "\n",
    "\n",
    "### Whatâ€™s Next?  -- Short Term\n",
    "ðŸš€  I have a few other analysis models such as: insider sentiment analysis, macro economical analysis, geopolitical analysis and options analysis. I am in the near future going to add these analysis model to my Github.\n",
    "ðŸš€ I also have a tool file, where many of my tools are saved, which are used with my other analysis models and these would then also be provided at the same time.\n",
    "ðŸš€  Both Agno-agi and Langchain is constantly evolving and updating, so double check the versions of everything before you run this file. This makes it also possible for me to add some other Agents I have been working on. \n",
    "\n",
    "\n",
    "### Whatâ€™s Next?  -- Long Term\n",
    "ðŸš€ Optimize performance using Cython or better function calling inside the Langchain class as these are compute heavy classes  \n",
    "ðŸš€ Expand capabilities with different analysis tasks and other use cases. I have for example a case where I have tested a Machine Learning implementation of these Langchain classes to gain insights tigether with other tools inside the Agent.\n",
    "ðŸš€ Expand datasets and expand the use of different APIs, for example analysing the supply chain or an deeper legal analysis could be an interesting use case \n",
    "\n",
    "\n",
    "### Want to Work Together?  \n",
    "- I am open to discussing AI/ AI Agent development opportunities or general Python development/engineering opportunities!\n",
    "\n",
    "**Reach out to me on my socials!**\n",
    "- https://x.com/marcusjihansson\n",
    "- https://www.linkedin.com/in/marcus-frid-johansson/\n",
    "\n",
    "\n",
    "\n",
    "### Thank you for reading!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial_agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
